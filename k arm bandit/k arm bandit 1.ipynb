{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k arm bandit \n",
    "\n",
    "this notebook is an attmpt to create a k armed bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variables\n",
    "k = 10\n",
    "reward_range_min = 1\n",
    "reward_range_max = 10\n",
    "std_min = 1\n",
    "std_max = 1\n",
    "samples_per_distrib = 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [5]\n",
      "1 [4]\n",
      "2 [2]\n",
      "3 [9]\n",
      "4 [7]\n",
      "5 [5]\n",
      "6 [10]\n",
      "7 [6]\n",
      "8 [9]\n",
      "9 [9]\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n"
     ]
    }
   ],
   "source": [
    "#create arms and rewards\n",
    "reward_stack = []\n",
    "max_mean = 0\n",
    "best_arm = 0\n",
    "\n",
    "for i in range(0,k):\n",
    "    #select mean for this arm\n",
    "    current_mean = np.random.choice(a = list(range(reward_range_min,reward_range_max+1)), size = 1)\n",
    "    \n",
    "    if max_mean == current_mean:\n",
    "        current_mean += 1 \n",
    "    \n",
    "    if max_mean < current_mean:\n",
    "        max_mean = current_mean\n",
    "        best_arm = i\n",
    "        \n",
    "    #to debug\n",
    "    print(i , current_mean)\n",
    "    \n",
    "    #select std for this arm\n",
    "    current_std = np.random.choice(a = list(range(std_min,std_max+1)), size = 1)\n",
    "    #to debug\n",
    "    #print(current_std)\n",
    "    \n",
    "    #draw samples for this arm\n",
    "    current_arm = np.random.normal(loc = current_mean, scale = current_std, size = samples_per_distrib)\n",
    "    #to debug\n",
    "    #print(current_arm)\n",
    "    \n",
    "    #append to reward stack list \n",
    "    reward_stack.append(current_arm)\n",
    "    #to debug\n",
    "    #print(reward_stack)\n",
    "    \n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bodies': [<matplotlib.collections.PolyCollection at 0x22e5ac52af0>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac52d90>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac6c0a0>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac6c370>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac52520>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac4ce20>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac6c670>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac6c910>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac6cbe0>,\n",
       "  <matplotlib.collections.PolyCollection at 0x22e5ac6ceb0>],\n",
       " 'cmeans': <matplotlib.collections.LineCollection at 0x22e5ac528e0>,\n",
       " 'cmaxes': <matplotlib.collections.LineCollection at 0x22e5ac7b4f0>,\n",
       " 'cmins': <matplotlib.collections.LineCollection at 0x22e5ac7b970>,\n",
       " 'cbars': <matplotlib.collections.LineCollection at 0x22e5ac7bdf0>,\n",
       " 'cmedians': <matplotlib.collections.LineCollection at 0x22e5ac882b0>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAHpCAYAAABJFhAdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde5hsWVnn+d+7IyIjM8+likshZUtZMqhleXmQLkfL9gL0Q9fT2v00tjOWMI3gY0s5KK2j0yiiLd4Q0RYYBK3CVtBWqLHtUVBoFC/TI5SXAn2gKMq2W0SwCiioqpN5TmbGZceaPyLinMjIuOyIWLn3Xmt9P89zqBORkcHKOJF7/+Ld71rLnHMCAAAAsLms6gEAAAAAsSBcAwAAAJ4QrgEAAABPCNcAAACAJ4RrAAAAwBPCNQAAAOBJs+oB+PTYxz7WXX/99VUPAwAAAJF7z3ve80nn3DXT90cVrq+//nrdfffdVQ8DAAAAkTOzD8+6n7YQAAAAwBPCNQAAAOAJ4RoAAADwhHANAAAAeEK4BgAAADwhXAMAAACeEK4BAAAATwjXAAAAgCeEawAAAMATwjUAAADgCeEaAAAA8IRwDQAAAHhCuAYAAAA8IVwDAAAAnhCuAQAAAE8I1wAAAIAnhGsAAADAk2bVAwAAIDW33n7XsdsD52QymR1/3J233VziqAD4QOUaAICK3fvAnu594ELVwwDgAZVrAABKNl2RfuZr/1iZGZVqIAJUrgEAqJhzkqt6EAC8IFwDAFAxp2HABhA+wjUAABUbBmvSNRADwjUAABVzclSugUgQrgEAqBo910A0CNcAAFSMnmsgHoRrAAAqNlwthHQNxIB1rgGUYnpHullY4xepcs7JOVv+QAC1R7gGUIl779+TTLrx2vNVDwWo3IC+ECAahGsApZiuSn/9z71bzYwd6YB84EarhVC5RpqKXNmUwrm6Sc81AAAV6uUDScPWEADSvQ/sDa9uBorKNQAAFeqOw7Wkfj5Qs0HdC2mZrkjfevtdGjgXTKV6Gr/BAKpBlQ6QJPX6g8t/HwdtAOEiXAMAUKHJQN3r86ETCB3hGgCACk0GairXQPgI1wAqQX0OGOrm+cTfCddA6AjXAABU6Kh3JVB3evmCRwIIQenh2sy+yszeYmZ/b2bOzJ438bWWmf2kmb3PzC6Z2QNm9mtmdl3Z4wQAoAyT1epOn8o1ELoqKtdnJd0j6TslHU59bVfSUyT9+Oi//0LSEyT9FzNj2UAAQHQ6E5XrLuEaCF7pgdU59zZJb5MkM3vD1NcuSHrG5H1mdpukD0j6PEnvL2eUAACUo9O/0gpyRFsIELwQeq7Pj/77cKWjAADAs3zg1M9ZLQSYFvKk91qHazPbkvTvJb3VOffROY95vpndbWZ3P/jgg+UOEMDa2EMGOF61loZtIWyDDijodF3bcD3qsf6Pkq6W9M3zHuecu8M5d5Nz7qZrrrmmtPEB2EzAx03Am8l+a2n4oZNJjUDY54hahutRsH6TpC+S9I+dc5+qeEgAvAv50An4MStIE66BsNVuBQ4za0l6s6QvkPRU59zHKh4SgFPAlW9g9uogw1aRVvmDQSVuvf2uY7cHzikzO/G4O2+7uawh1ULI7VGlh2szOyvpSaObmaTrzOzJkh6SdL+kX5f0JZL+uSRnZo8fPfaCc2566T4AgQr3sAn4M7k741gv57cjZR98YE9mphuvPb/8wailKirXN0n6w4nbPzz680ZJL9VwbWtJes/U932zpDec8tgAACjNUW9G5Zrl+JIyXZH+ute+S61mllylelrIHzGrWOf6jySdvN5xxaKvAYhEwFf8AG9mLb3HcnxpcxIHSCnodF3LCY0A4udCPnICnszquWaXRnB0DPs1IFwDqEbIR07AE8I1poU8kQ9DhGsAleD0gdQ559Sb1RZCuE4e+Xq4akqoCNcAKhHwcRPwope7mb8HHXquk8ahcSjkcwThGkAluPSJ1E1vfT6W5075gN+PZDkCtlPY83II1wAqEe5hE/Bj1jJ8V77GcnypYrWQYfEl5JeAcA2gEs5RvUbaFgXogy7hOlUu6JotJMI1gAo45ziBIHmLAvQh4TpdtIWMii9Vj2J9hGsApRv3k4Z88AQ2ddDtz/3aIW0hyRoEHix9oOcaAFaUp37mALS4Or0oeCNuzrmgl6HzgZ5rAFjRlcp1wEdPYAPOOR3NWS1Eoi0kZQNRuXYKuzWGcA2gdJfDdcXjAKpy1BtosGA566N+zofPBA0rti75f3vnFPQnDMI1gNIRrpG6ZT3Vg4HUYafG5HRHGwilvsz5cNK71A90QyXCNYDSMaERqSvSU81yfOnp5ePCQ9oHx/FP3w/0UwbhGkDp6LlG6vYOl4frC4e9EkaCOumNrlakfmgc//yEawAoaHy5O8zDJrC5Rw66Xh6DuPQut4Wk3Xc9rtzTFgIABY3DderLTSFNnX5eqOXjkcNe0gErRd2JMDluEUnR+G0f6mtAuAZQui6XPpGwRw6KtXvkudN+h/WuU9KdmMTaDbRq68P43JDTFgIAxXRzKtdIV9FwLUkXVngswnfUG0z8Pd0JreO2kF6gHzAI1wBK1xmdNAItSgAbeXiFXupVHovwdSY2Fkp5KUYmNALAisaVa+ecBoEePIF19PKBLh4Vb/VYpcqN8E0G6qQr1+NwTeUaAJZzztFXiGSturxetz8otCY24jAZqDu9NI+N+cBdbgsJtXpPuAZQql7ujk1kDPXgCaxjnUr0w1Svk5APnPoTq2Mc9dOsXE+2xoRafCFcAyhVZ+qEMX0biNmFw9V7qJnUmIYTx8ZEK9eTVzZDfQ0I1wBK1Z2qVE/fBmLlnCu0M+M0dmpMw9FUkEy18NCJoG2QcA2gVNNtILSFIBX7nf5a6/Ze6vSDXZIMxU2H6X7ugp3Qt4nJanWvPwhy0jvhGkCpLk1tijF9G4jVJu0dVK/jN125ltIsPnTzfOp2eK8B4RpAqaZ3nFtlWTIgZJsEZMJ1/GYtvZficnwn2mMC7LsmXAMo1d5USDjo5lzyRhI2Ccisdx2/wxlBetZ9sZuuVHfy8F4DwjWA0hz18mNLTY1RvUbsjnq5Drvrh4S9o56cC6/3FMUdzXh/pFi5jmHSO+EaQGn2jmZX3/YJ14jc9BWbVeW500XmJ0TLOTezSn2wwQeyUE1/oJjVi153hGsApZkXoueFbiAWPt7j9F3H66g30KwLE5tc7QjRrKubIX6oJFwDKM28cE3lGrG71Nk8JKVYxUzFvN7q1HquZ50L9gMsvhCuAZRm3kHyoLve+r9AKHwsOcmylfGaF6L7uUtqwvesKnWnNwiu75pwDaAUnX4+d0kl55jUiHgNBrP7aVdF5Tpei9o/UqpezyvAhNYaQrgGUIpl4Xm/E96lP6CIw14+s5925efp5lzhidTCcJ3Qh6p554nQii+EawClWNZXvXcY1sETKOpS1997+8Djc6E+FlWnUwnX/Xww9+pMaMUXwjWAUixbLYEVQxArH5MZx2gNidOiD02p/Jsv+j0JbdI74RpAKZbtMHep01c/oYk7SIfPiYhMaozPQbc/c3OtsVQKD4uq0wfdvgYBtUQRrgGcusNuvnS2t3Os44s4+aw8plLFTMmy414qhYdF1enBwG971WkjXAM4dY8cdgs9jnCNGPlcRqwT2JJkWG7ZfBPnwmuLWMeyFUFCWjGEcA3g1BUNzY8QrhEhs3o+F+qhyPEx9sKDc275ilIBfcAgXAM4dcv6rccuHPbkfKxZBtSIzzxMto7LYOB0scBKGLGH60sFlpkMaadGwjWAU9XPB4UnYeW50yV6ShEZ81huzihdR2X/qK9BgU6f2Cc1FlnHeu+oH0zxhXAN4FQNq9HFH//IQbH+bCAUtIVgnqKhudMb6CjinRqLVKXz3M9Op2UoPVyb2VeZ2VvM7O/NzJnZ86a+bmb2UjO738wOzeyPzOzzyx4nAD9WvZwZ++VPpMdntZnKdVxWOd7tRXxs3CvYTx3KTo1VVK7PSrpH0ndKOpzx9RdJ+h5JL5T0JZI+Ien3zOxcaSME4M2qkxQvFOzPBkKRkYcxxyqBOebWkKL91EVDeNWaZf8fOufeJultkmRmb5j8mg0b075L0sudc78xuu+5GgbsZ0u6vdTBAtiIc27lSvTBaE3srSZda4jDrGLzK95x37HbH3noYOb9L7rlhmO3qVzHo9ufv933LLFe1Tvq5Qs30ZkUyqTG0sP1Ep8l6fGSfnd8h3Pu0Mz+q6QvF+EaCMpBN1de8KA56cJhT9eca5/CiIDyzZrQOA7TY+P1q6fvP/lc/saFaq0alvcOh7sUZpFdClmlIh/Kcnx1C9ePH/3341P3f1zSP5j1DWb2fEnPl6Trrrvu9EYGYGXrbtV80O1LIlwjDluNk1dhnvDo3WO3x6F6+v4Tz8UVnWhcKLi51lg+cNrv9HXVTuuURlSNVQJztz+c2LndapziiDZXt3A9Nl3qshn3DR/o3B2S7pCkm266KYw1WoBErLujVkg7cQHL7GydDALT7R7jdpDp+6ftznguhGmdNo+9w1504XrVSYqXOn3C9Yo+Nvrv4yV9ZOL+x+lkNRtAza3STzjpUieM5ZZWdevtdxV63J233XzKI0GZfAbi3VbdTttYx2Cw+nwUabgh1xMefQoDqtCqVzgvdXI95uwpDcaTul1f+pCGAfsZ4zvMbFvSV0p6d1WDArCedSvQl7ppVK4/cP+ePnD/XtXDwCnzGYhnVcERnv1Osc1jpsU2qTEfuJWLMPsFdrSsWukfgc3srKQnjW5mkq4zsydLesg593dm9ipJLzGz+yT9N0k/IOmipF8re6wA1uecG/VOry7PXRB9dauarkh//c+9W3KOSnXkfAXiZsPouY7EukuOHvXyqI6N6xRgQriyWcVv6U2S/mL0Z0fSD4/+/iOjr79C0s9Ieq2kuyVdK+mfOOf2yx8qgHUd9vK1KjNj606GDA0TReK31czUbGy+wsPuFi0hsdikAh1T9Xqd4/ylTv23Qa9ines/0nCC4ryvO0kvHf0BEKhNqwsh9NVtqu4nCPizu9XceIc9JjPG45EVVwo59r0HPX3a+W2Po6nOOpXrfDDcBr3OHza5vgTgVGxaeU6l75p8nQYfwZh+6zgc9XJ1eutf1oupch3rilKEawCnYtNwnEJbiBNtIanwEYypXMfhkTX7rcf2j3rKB3EcOdY9zte975pwDeBUbNwWsuYyfkGJ4/yIArxUriOZxJa6dSd6jzk3nNMSum5/sHYFf9W1sctGuAZwKjatXPf6A3X7G8yIDIATfdep8BGMaQuJw9EGLSFXniP8cL3Jh4y6tw0SrgF418sHyvPNQ+NRP/wTyCIE63RsunRaIzO1m4TrGHQ8HNc6ERQeNqm+171yT7gG4J2vA/8mk35CQbxOw3aroWyDM24s6xrDz/GxU/NwWcQmFfw8d+rl9T0/EK4BeOfrwO+jwlNnw7aQqkeBsuxssFMjkxnj4aOlw0drSdUON5xXU+fqNeEagHdHnirXMZxAFnFOctSuk7FJzzT91nHIB059Dy1zMRQeNm37q3PfeX1X4AYQLCrXxThHtE7JJtVnVgqJg69jWgw910cbVq6PuvV9DahcA/DOW891BCeQRWgLScsmAZnKdRx8zSOpc9W2COfcxpVr2kIAJIUJjcXQFpKWTSYlUrmOg68VkPq5C3ojmU5/oMGGh/c6f8AgXAPwjraQYpwcy4UkZLu1/im33eR0HQOfBYOQj48+gjGVawBJ8TWhMfTqzDKObJ2UddepbjZMzQan6xj4XD4u5E22fExWJ1wDSMZg4NTzeNAPuTqzDDs0pmWrma211jWbx8Sj77FYEHLhwUcwrvNa14RrAF75noQY63J8zjlptFpIyCdJrGadoNzeoJ0E9eLzdz0P+IO5r37puvZd8xsLwKv+prNUTvn56qI/uDKVsa7VF/i3Tu80/dbx8BquA/5Q7i9c1/PYyW8sAFRgciMJn5eKUW9rVa5pC4mGz2pz2OE67iUJCdcAUIHuRLXaZ4866m2dFg8q1/EYULmWFP9mOvzGAvDK++E+3PPHQv3JcB1p6wtO2qbnOmlMaBy2wfnYAl6icg0gEb7n2IR5+liuN3Fy6Xk60aD+1gnKm2w+g3rxWbkeBDqh0We1mXANALhschJjnwmNyWBCY9p89lyHOlfDZyCu64TGZtUDABCZOcf7V7zjvmO3P/LQwYn7X3TLDSefLszzx1KTJ0ZWC0nHqlXoLJO22EAmGrMC8Qvf9N5jt8eV3en7X/Ospxy7HWpbyKxwXeT8IJ08R3T6uZxzMjPPo9wM4RqAV25Ouh4fLMfGJ5Dp+1MxGahpC0nHqkG53WzULjhgAx5/1UMtPMxqC1n3/ODccHJ43VbUIVwDKMUTHr177Pb4oDl9/7R5YT10k1sXU7lOR5aZ2q1MnYKXs2kJictWM9Nh93jldroiPa7WzrqSN/1cIWrM+LC47vlh3vNVjXANoBTTJ4qiJ5BQqzPLTC7FV9flpHA62s1G4XDNZMa4zArXaz9XoO1CzcbJMLzu+cFMatbwdajfiAAELdYw7Ntk32HRoIU4bK+wYgiV67j4DMShLtHY8vgaNLL6Va0lKtcAPMs8X6Lz/Xx1MVmtruukHJyOVfpDY65c33r7XYUed+dtN5/ySMrjs5Uj2Mq1x0DsM6j7VM9RAQiW72rKKlW+UPTzgfKJSYzO0RqSEirXs937wJ7uuf9C1cM4VV7DdaDvjWbmb9w+g7pPVK4BeNVuZjLz1x4SY+VuVpDu9AdR/qw4aWer+L/zKo8NzXRF+tbb79JRL4+qUj3NZ7U51HDdavoLxHXst5aoXAPwzMy8hUSzcC99LjJrnddOv547jcG/89utQo9rZKaz7bRqYLFP2fB5JSLUY6PPPunWjMmRdRDmvwyAWvPVyrHVzJTV9LLfJmZWrpnUmIztVqNQ1fHcdjO5PvzYJ0T7qjZvNbNg3xstr20h9Yyx9RwVgKD5WtB/J9I2idltIVSuU3J+Z3n1ushjYhPruvZjPsN1qLLMvFWvqVwDSIavtpBYe5BntYUcUblOyvnt5e0eRdtHohJ3tvbWyhFyuJb8tcfUbWfGsbD/dQDUkq+2kBhXCpGkS51+ofsQr2KV67T6raXos7WajWzmJiqr2q5pqCzK11WZq2p6dSfOMxeASvmqONe1KrEJ55z2Z4Xrbl+DQezRAmPLqtLNhml3K71wnQIfx8fQCw8+QrGZdLbAFaAqhP2vA6CWaAuZ76CbH1vjemwwkC52qV6nYquZLVxmL8V+ayn+CY2Sr3Ad9rHRR8vT2XaTHRoBpGPbUz9d6NWZWfaOevO/dthLos+2yM58Ma91PHZ+u6XD7uyJrCm8D2aJfUKj5Oe4Fnq4PrfdVJYNiwrrqvMH0PjOXAAq562vMPATyCz7R/Or03uH6VWu731gT/fev1f1MCqx6JL2uZpe7j5Nzrn4m67lp1869MJDlpnOtjcLx3Xtt5aoXAM4JWfaTV04mF+lXWarmakV6CYJi+wdzn9N9hdUtWMyWZW+9fa75JxLolI97Ux7fsjajXhnxnmcksjWXnbdDH1CozScsLvoeLj8++sbruM7cwGohTMbTsY6E+HOdPMmM46lOqkxvZ94aNHvyKa/PyFyLpGe6w2DcSyba23S+tRomM7U+AMo4RrAqdh02+YYt32eN5lxbDDQwvCNuOy0Gpq1yd7OViOK8LSqYeXaDdtDItbesKUjlna5Tdo6ztd891LCNYBTseiSdxnfX0eLJjOOpdIagmHf6axdSFNsCZF0OVT3I796025mMz9UFRV6v/XY7lZDjTXn5tR9wm8c/0IAamfTto4YK9dFJixe2KAHEeGZ9XsS43u/iHGkziMP12a2UfU5lsq1mencmu/1c4RrACnabjU2WjEkxp7rhw+6Sx+zySRQhGfWFZrdCN/7hYwydezhWtrs+BbTh691N4Gp6+YxY4RrAKdm3ZNAuxXfSiG9fKCLC5bhGzvo5ur0Z699jPjM2oWxzhO1TtM4UsfeFiINe4bXFdMyjeucI7JM2q159T6usxeAWlm3OhNj1XqVdg+q1+mYtSpIqtuej3uuU6hcr9vWkGVxVa7PrbHW9e5Ws/YTfmsXrs2sYWY/amYfMrOj0X9/zMzieTcBiVj3JBDTyWPskRUC8yP0XSdje+v4abiRmbY87XAamvEiIb18g237ArFu9flsu1XrVTJWtc7E9RDOD3Uc4fdK+nZJz5X0fklfJOmNkjqSfrTCcQFYEZXrKx4p0G899vCl4o+NQeQrry201Ti+ckQ70WAtSYNRY0i3H3+43m41tNXMVv5ZY2oJkYa7+e5sNXTYLd4KF8JrUMcRfrmktzrn3jq6/bdm9hZJX1rhmACsYd3l9GLrOR0MXKFl+MYudvrq5wM1I+s7nyfhbC2z45XqTddADtn4Q1Y3gcq1NAyJn7q42gfpOu9KuK6z7eZK4TqEynUdf4v/WNLTzOwGSTKzGyU9XdLbKh0VgJW1mw211qjExVa53jvqabBCXnAurSX5Yt80ZJnJpdXaEWxrva7B6H2QQluItF7fdQhV21WtuvJH3VcKkepZuf5JSeck3WtmuYZj/HHn3OtmPdjMni/p+ZJ03XXXlTZIAMWcbTf1cL94dWZnqxHdSiEPrzFB8eGDnh5ztn0Ko0HdTLaCxLJByDouV64TaAuRVl8xxEw6G+Fk11XWum41syA+gNbxt/hWSd8k6dmSnjL6+wvM7FtmPdg5d4dz7ibn3E3XXHNNicMEUMSqlZYQLvmtap0qdFqV66pHUK3JsBBCcDgtjsr1Qmfa9V8lYx2rVKJDOT/UcZQ/JemnnXNvHt1+v5l9pqQXS/oP1Q0LwDpWbfGIrSVEkg46y9e3PvE93dW/J1SJZ+tjletUJzT28sHl90Enkcr1ztZwo61+Xuw3IMaWEEnaaTXUyKzQEoyhvAZ1/C3elTTd2Z6rnmMFsMSqlYZQDp5FDQZOh73VN4Xp9AbqJ1LBS73nenISY6qV68lWkF7BsBmDVY5352u+5fe6zEy7BSexh1J8qWNgfauk7zOzrzWz683s6yR9t6T/p+JxAVjD2XZTqyzLGsplv6KO+vnabQ/rhPIQpROlZjvWFpJoz/VkK0ivP0jmA9cqYTGUYLmOoq0hoZwf6jjKF2q4nvXrJD1O0gOSXi/pR6ocFID1NDLTTquhgwJLLWWZClcwQnGps35APujma+/kFpJEctRcrYZN/D3NcH3UO36VptMfHFtFJVarhMVQguU6iv5soSzTWrt/KefcvqTvGv0BEIGz281C4frMVjOq3cckrbR+67Qir1kMUqlSzjMO1Kbhh9EUTc8xOOjmhOsJW80s6p07i7wOwx71MF6DMEYJIGhFTyAhrF+6qksbTEy8tMZEyBClHa2l5ihQx/bBchXTHyRTee8XbfWIuSVEKvbzhVS5D2ekgbn19rsKPe7O224+5ZEA1Ssams+142uB2KT6nErP9aDAKgExazYymbTS3ITYTP+epPLebzUytVuZOr3Fk5dDCpbr2G4tXzklpA8YVK5Lcu8De/rA/XtVDwOoRNHQvO526XW2SVtIKtW7NNZEWczMZEo3XU9f4UnlvS8VC84xXtWbtmzllJBWkgpnpIGZrkjfevtd6vQHVKqRpO1WVmgd05AqE0XkA6ejDSpw/dyp2x9E3WvpNOy5ds4l3RZhlm7lutPPlU9VLDf5UBqas+2mPnVx8S62Me7MOO1Mu6mHL83fPCuk80O8R+yacRP/C6TGzLSzZJZ3I7PoJjD52Agm9s1kxpMZi2wgETOTJRuuZwXpw16eTLtQkap0jFf1pp1Z8AHCTNoN6PxAuC6Lc8kvN4W07Sw5MC4L3yHaZBm+y8+RSAWvn0iQmsdMyhJtC5n1Hncunb7rZRXZYT9y/HFt0TKsO61GUFu/x/+vVRNO1K2RtmWVl9jWt5Y2WylkbJ2t00MyLjokX7lOuC1k3nvcx+9PCBZVbCVpN4GqtbT4Q8ZuQC0hEuEaQEl2lp1AIgzXB1SulxpH6uQr14lWraX573EfV35C0Mhs4byKZVf9YtFuZnPXeQ/t/EC4Lolz7EKGtC3rl1sWvkNE5Xo5eq6HhkvxpRmw9w5nT2Kbd3+MFrXFpRKuF83NIVxjpmFbSNonD6RtWU91KNvaFuWc8zIZMfaJXVcq14kvyGdKsnZ92M3V7c/+t987SihcLwjQMc5HmWdei8yy1pm6IVyXxTmarpG0RZf8JEW3UshRbyAfedE56SDiiV3jK3q9BZtHpMAu/09aFgXoTm+w0VKWIdluzY9jsR0bF5n3QSK0DxiE65IwoRGpW3TJL8Zl+HxOxoq5NWTcFtLP065cW6KV6wtLWj9SaQ1ZdPxLpS1Emj3xvdEI7/xAuC7JsOeaeI20zTtJhFaVKMLHZMaxi1GH6+F/e4mH61SnNC4Lz8vCdyzmHRuXTXaMze6M9o/QWkIkwnVpBqxzDcxdji+0ySpFdHN/4TrmlonB6JpezD9jEcO2kLTi9WDglvZVp9J3Pa/AEFrFdlOzzgUhnh8I1yVxklKvywDzVgQJ8eC5jM9CbMwraVC5HkmwLeRit790XsLeYT+Jq77bzXSu6i3SamRqNo7/JoT4AYNwXZJxW0gKBwlgnu05lzdDPHguM/D4u+7zueqGCY1DKU5ovHCwvCqdD1zUbVFjWWZqz5jUmFK/9dj0+SDEDxiE65JcnrQTcQUKWGZeiCZcLxZxtr58bEy+cq3ksnXhfuqU+65TDNfTP/O8okydhTfiQF1eyzXx6gzSllS49tkWEnG6Hr9MqR8bUwvWUvGVQFIJ17OOg9tb6cW06dchxPNDev9qFRmfG7tUZ5CwRmZqzahChFiZWIa2kOUmW+WSr1wnNpmx2x/oYM6259NSCdez2h+oXIcZrsNb3yRQ45PjvJ2oYnXr7XcVetydt918yiNBXWw3M/Umfg+aDVOzQbheJNa5GpPFhnzg1M8HUb4XcNIqq4AcdHL18oFakb83aAsZmtxQp7Vk87G6IlyXYLI60+mnsdvUPPfevyeZdOO156seCiqy3Wpo/6h/7HaMZoXrF77pvcdud0YfMqbvf5fLFO4AACAASURBVM2znnLsdqxF3c5UsaGbeLgOL0Ksb9Vq9N5hT4852z6l0dTDdJCOtfCwTHvidQj1wwXhugSd/uByz/VRL9Kz5BzTFen/9effrcyMSnXCpi99hnrwXMbn3OVY20I6U8fDTm+g3a2KBlOx1Na5XjVcX0ghXCdybFxm8udetC18nRGuSzB5Akm9ch1nRMAqptdzjbVyPetK5nRF+hXvuE+S9KJbblj4XLFGrunj4XQlG3Fyzq28rXkKfdftZqZsIkvO2q0wBVvNTCaTkwv2/JDmv1zJJk8gqVWuT3CKNymgkOlKRKiViWV2Wk09LD+B4Ew7zkP19PHwqJdO8WF6Psp9H9uX2cn7Y7zKd6mbr7w6TArh2syOFR92ElwpZCwzKXfzN9epuziP2DVzROUauKwdwUzwInzuOhniJgpFTE/wTnk1pc//9HTmoawTlPu500G3H301d3trsiUizt/7IsxMcu7Ebo2hiPtdWhOTgXq6xzA1tIXgROU60MrEMrttfz9XjNvDS9LRVLEhpcp1jBXpoorszDjz+w578YfrZviT+XwYTz8INVyne82hRJOV63zgWM8VSdtqZMfmbc3a8jcGPkNArIHiROWanuskrLIM36QUWkN2qFxLutI92szCPD+EOerAXOr2j90+6KRTnTkh0lUPUJyZHVuvNta1a3c9nhijrVz3pivXhOvYDQZOlzr95Q+cYXIJz1htTWyotRXh5lpF2agCQ+UaM806kOx34v/0PQ/RGtKVk4aZBblBQBFZZl4qT61mFuUHkMHAnZjU1s3zaDfMwdB+p792jeXiUT/690drFCZN8RYeihhf3WxRucYsl7onDyQpfPoGFhmH69gPQD76rs9EWrU+nNFfPRiwHF/s9tdsCZGGbZWXCm6ZHqqtxpXCQ8out4VQucYss4L0xTUvicXA58YaCFcqJxAf7RyxrhQy3S43dhB5eErd3uFm579V18cOTevysbHigVTscltIoFc2C4drM8vMrDl13y1m9j1m9sX+hxaHWUE6hUtb88S60xxWc7lyHeZxs7Dd1uYTEWOdzHg4J0QfzAndiMMmlevh98f9/hiH6yzxdG02DNihFmBWOWq/SVJH0jdJkpl9m6TXjb7WM7Ovdc690/P4gjfrQJAPnA57ebQnzUVS/VCB41KpXG972AQi1uW4Ls2Z2E3lOl6DgZt7xaKoTcN53U32XKfMFPZrsMqR/8skvW3i9r+V9AuSrpL0nyW9xOO4ojGvBeRi5J++56EtBFI6lWsfExpj3cHysEdbSGoudvsabNhSvx/5ld9xtTb2wsMyw9eg6lGsb5Wj9uMk/b0kmdmTJH2WpJ91zu1L+iVJX+h/eGE76uXqzZmcs5douJZYMQTHVwuJmY8NcmJd63ZeiKYtJF4+WjpSmNSYiZ7rlCrXe5IeM/r7UyV90jn3vtHtXNK2x3FFYdHExXXX+Qydcy7qqgOKSaVyvdXMNlpq0ExqR7jWbT8fzN2t9rDLcnyx8nXFNvbzp5lFf2wsJtwXYZWm33dL+j4z60v6Lh1vEXmSpI/6HFgMFh0AYj84zOMclWuk03MtDXegXHfjqHazEeVrNGsZvjHnlOyclNj52p049l2OzSQLOFj6MJzQWPUo1rdKSeRFkh4t6S0aVqlfOvG1WyXd5W9YcVhUuT7o5soTbEB2l/8HKbu83FTF4yjDJm0dsfZbL+urpu86Tr7OebGfO0MPllihcu2c+2tJn2Nmj3HOfWrqy98p6WNeRxaBebPhL3+929f57VZJo6kH51gxBFfaQVI4gWzSd51av/Xlr3dy6WxJg0Fp+p5Csa/nqavUq9ZSWj3XkiTn3KfM7KyZfaaZtUb3vd8596D/4YXLuZPbnk9LbcWQwcDJySnuC3oowiyd08cmm8DEWrlethHIXuTLraWKynVxMbaDrWTYGxOslY7cZvbPzOy9ki5I+h8arRBiZr9gZs8+hfEF67C3vO0jtb7r7qhPjsI1JEmJLDe1SUBue1htpI4uLAvXke/Cl6r+puvwjZ8nj/skksBhcalh5TrcF2KVHRqfKem3JH1S0vdOfe+HJD3X79DCVmSL89S2Qb8SruM+MKKY0C/7FbXJxLwz7fgm9R12c3XnLFE6dtDN1enTdx0bKtfFpXBsXCbkDxmrlFR+SNIvOef+iaRXTX3tHklf4G1UEVjWb130MTEZr/mdwHERBYR84FzFmQ3aQs6046tcL6tar/o4hMNfz3XczYWmdI6Pi4T8EqwSrj9P0p2jv0//hjysK2tgQ8VaPo4KtI7EhMo1JmWJnD2ajWytiYmtZhZlW0jR0ExrSHxyT+0csZ83Ezk0Rm3VTWQeO+dr10tiQuOEowXruE5atN5rbHr94QEx8uMiCkrp/LFOBXqTinedPXLQLfQ4Ktdx8RmIY18tJK2j43whz8lZJVz/nqQXm9nVE/c5M2tL+g5Jb/c1KDO71szeaGYPmtmRmd1rZl/t6/nLUDQ0p7TVbzcfviaOha6hsA+cqzq7Ru90jP3W+cAVnmuyd9jnKldEfLZyDCIP18O2kHSOjzFa5ej9Ekl/JumvNNyd0Un6PklfJOkqSc/0MaBReH+XpD+W9LUaVsSfKOkTPp6/DPnAzd3ad9pRN+7esUldKteYkNK5Y3eNoLxOIK+7vcNe4dWC8oHTfie9vQBi5bNNOo/9Q1fYq9B5E/I5onDl2jn3t5KeIum3JT1DUi7pqyT9iaQvdc7d72lML5L0gHPum5xzf+ac+5Bz7vedcx/09PynbpVWj5TaQiZ7rmOvPGC5VHquJensGiuGxFi5XrXV48IBrSGx8BmIo++5rnoANRHy67DS0ds591FJ33JKYxl7pqT/YmZ3SnqapPsl/YKk17pArhEerrB1b0rhupdfKV1084G2szh7SlFMyAfOVa3Vc53wSiGTj3/CKY0F5fIZiAdhRAEkrI6lkSdKeoGkV0p6uaQnS3rN6Gs/O/1gM3u+pOdL0nXXXVfSEBcrOplRSqvnerJVppcPot3aGQUllK7HK4YUPTbEulLI/oq70q76eNTXrKuVL3zTe4/d7oyWa52+/zXPesrUcw2fL8sSOogkKOR/3cLh2sx+cclDnHPOR1U7k3S3c+7Fo9t/YWafLenbNSNcO+fukHSHJN100021+Dh7sELl+qiXyzmXxOSF8YRGSUs3kUD84n/HH7fbLh6uY1wppJcPVio8SMPiQz5wahCigue7T3rgnLJIjyJx/lRrCDgXrVK5frpOrm/9aEnnJD0y+uPDA5Lunbrvg5K+09Pzn7pLK1SjBwPpqDfQToQn00m9fHBsQkuHcI3EnG039dDFYsvQbbKrY12tU4V2briT7VU7TGoM3ay2kOmK9CvecZ8k6UW33LD0+foDpwgv7gwFHCrXdevtdx27fe8De3Lu5P133nZzmcNaW+EjuHPu+ln3m9lXSfp5Sf+bpzG9S9LnTt33OZI+7On5T93qlz570Yfr6Uo1lWukdvrYXeF3PMaVQi6u2eJBuI6D70mI9F3H7cZrzwe9aO/GR3Dn3H81s1dq2Bf9FZsPSa+U9G4ze4mGO0J+saR/I+n7PTz3qTvq5Ze3+S5q76ivx50/pQHVxIlwnROuk5dYdebMCtXo3QgnM+4drbfyx/5RT9KO38GgdL7DdcwrhqR1ZBwKpSJd1CqbyCzyNxqG4I055/5cwxVDvkHSPZJ+XNIPSnqdj+c/betc+iy6qULIpsM0lWukZpXAvEoQD8W6x7l1K96oF9+TD1OYp4RwbXwEN7OmpOdJ+ujGoxlxzv2OpN/x9Xxl2l+jOrPO94RmelOdTj+dJQgxW2qnxnazoWbD1M8XV9yyTNpu+ap71MNg4HRpzXC93+knM+k7ZlsNv+/pdjOu35FJvNXDt8pqIX8w4+4tDfuhHyPp23wNKmTrVK47vYE6/TzKpbfGJlcKkZjQiDSdaTeXboyyu9WMLkhe7PYL78w4Lc+dDnt5lJM8U9L2+IGxkZlansM64NMq785Moy3vJ/7sS/rPkv6xc+71/ocXnnXXZY19PdfpME1bCCLLj4UUmdQYZUvIhsc3WkPC57PSHHPVGnFYZbWQp57iOKLQ7a++juvY/lFfjz3b9jyi+pjetbKfO3X7A21xkERCigTnGCczblo8SGHSd+y2GpnMtPYVjGPPxXkDNcc71KNNJibG3HftnNP+jNcmhYmcwKQiwTnKyvWGv+vr9mujPszMWyiOuYUScVh4FDezb1rlyZxzv7zZcMK2d7h+QI65LeSwlyufMYlr/6inR5/ZqmBEQDWKrF8dY+V603DNB/E4tJuNE5Pb13qeyCb8Ij7LjvRvWOG5nKS0w/UG1efDbh5tm8S8Dw4xf6AAZtluNpZeGo+tcr3O2v/TDru5+vlATSaxBc1XrzQ916i7ZUfxzyplFJHYNCzuH/X0mAj7rue1vGzyYQThS3A+o7LMtLPV0EFn9tyM7VZDDc/rAVfNV0vHxU5fV+9ypStktIUgFQvDtXMumC3Hq9btD05M2lvV3lE/ynC9N+dDx0EnVz5w0YUJYJEzW8254ZqWkMXPQ7gO23bLz/s79so1Z8Twxf0OLZGPCYmb9GzX2aKKfswTOYFZziwI0LG1hEj+2r/ouw7fovf+as8T3+8J4rLSO9TMbtFws5jPlbQ9/XXn3BM9jSs486qzqz1HfEFzWb/l/hHVqHSlWZ9ZtBlKkXWwQ+OtLYQ5GsE7125t/BztVhbl3KTj0jw2xqTwO9TMvkbS2yTtSrpB0n2S/k7SEyQNJP2/pzHAUPioOo93aozJsqoVkxqRmkXV6dgqcs45XepSucbQzlZDjcZmwbHIijtA1Vb5+PeDkl4r6WtGt39gtLHM50tqSHq736GFxVtfYWRhc1k1PsZqPbDIor7q2CrXB91cA0+bsfZzt/YmXaiPcxuG43PbhGvU3yrh+gZJb9WwSu00ailxzv03SS/VMHwny1fFeXqb8NA9dKm78OsXj/rRVetRUKJXPluNTK0Zl7UbmXmb8FUXh57D8KaTxlG9sxuG47MeWkuA07ZKuB5I6jvnnKQHJV038bX7Jf1PPgcWkl4+8Fad6UYUrrv9gS4cLK9Mf+ri4gAOxGZWhXonsqq15Gera8Rl07YOX5MigdO0Srj+K0nXj/5+t6TvMrNrzewaSd8j6W/9Di0cPgNxN48nXH/qUqfQ4z55sdjjgFjszKhQx9YSIklOftM1WT18m4TrLItzRR3EZ5V36a9K+rzR339I0jslfXR0O5f0bI/jCorXcB1R5bpoRfpTl7oaDJwy1rtGImYF6RjDNTBtk3C9u9XkPIEgFH6XO+deO/H395jZF0r6p5J2JL3TOXfvKYwvCD6rzbH0HzvnClek89zpkcOeHn2GJfmQhlnL8e1QkVvK0WcSvGYj085WY63+eVYKQSgKv1PN7L2SflnSm5xzH3fOfVTS609tZAHp9HyG6zgq1xcOe+rnxU+En7zYIVwjGbP6q2e1igSPLIwZzraba4VrVgpBKFbpuf64pFdI+oiZvc3MvtHMTmwkk6Ju7q/aHEtbyKp91PRdIyW0hSBl64bkc9usFIIwrNIW8k/N7HEa9lb/K0m/JmnfzH5D0q845/7wlMZYe92+v/JMP3dyzsks7L6yB/dXWwHkoJProNtfuHsdEItWI1NzYjONLJPa0e86d8Ur3nHf5b9/5KGDE/dJ0otuueHE91EIj8O6IZnKNUKx0jvVOfcJSa+S9Coz+zxJz9EwbD/XzD7qnPvMUxhj7TVmTLB44Zvee+z2uN1j+v7XPOspx25nmYIP1ke9fK0tjz91savdR3PwRBomP0jutJrB/97PMi8MjwO1dOXYOHkf4rZOSN7ZaqjVSOcDKMK2dpJxzn3QzH5E0gckvVzSZ3gbVWBmhet1ZRGcYB8+WG/d6ocudfWER+96Hg1QT5NtIDGucb3I5O/5OFQX+d1nPmMctlsNtZqZeiu0QcY8mfHW2+86dvuDH9ubef+dt91c2piwmbXerWb2dA2r1v9S0llJfybpJzyOKyizwvV0RXp8yXPWpc5JzSz8T+brbuG+TrUbAXNKdpdG6XgbyHYr/N/7WebVCiaPg0WPjZLfQgaqdW67qYdW2EAspZaQG689X/UQsKFVVgv5Ag17rZ8t6R9I+rCkV2vYb/3XpzO8MDQ9HvBjOHnsrxmSD7q5+vlATS79IQHt5pVq9Vak73nfP1erEf7xEUPnVw7X8U5mpCIdn1U+Cr5P0gVJv65hoP7/TmdI4fEZiGMI1+tWriXpUifXVbtxBg1g0tZE5bod4zJ8Ov4z+kDPbTxWDcspVa4RvlXerbdKeotzjjXTphCur+j0842WE9zv9HTVbrwVipSd6Ct8YE+y4/enVMGZDJ6xVq59h+FYX6cUrRKWt5qZtiP9AIo4rbIU36+f5kBCRri+YpOqtSRdpO86GTd+etp9he1jles4Q2OrkSnLpIGH5fubDWPr64jstBpqNqzQZmPndyi4ICxcZ/HAZ8+1z+eqwqXOZhvqbBrOUV8pVaWLSKFyLQ0DdsdDuo75NUqRmelRu1t6cH/5xfBHcTUTgSFce+DzclXoqwbsd3obfn984Xq6HWIewmdaWo1MpuGiKTEHx1YjU6fnIVwntMlOKoqG66t3t0oYDeAPRysP2s1s7pJTqwq9r2zTynOeOx31/G0nX0cfuH9PH7j/QtXDQA2YmTKLu93BVyhmMmN8HnVmeUW60TCdZzIjAsM71gMzU7vZ8BIKQw7Xzjld6m5eed4/6gf9Okybrkh//c+9W/18QKUayszkIt/U21dVnsp1fM62m0v7rq/eaUW5eynixtHKk50tPy/lTsChspc7LxOXOv24K9fOxR6nUJRZHLuyLuKr4kzlOj7jvutFln0dqCOOVp5MbgixiZArtr3cQ7LWMKTHzIltnDFkFv8mlW1PFWdfz4N6IVwjRhytPNnZ2jwUbzWzoJfi8xWu+56ep66cU/StACjGZN7ma9SVr4JByIUHzHf1gr7rRmZsHoMgEa498XHgD/3k0fUUin09T10556hcQ9K4ch13uvbV6uajgIH6OdduqjFnW/urdltRT/ZFvAjXnvg4gYTcby2p0GYARdAWglTY5f+Jl68NcrZpC4mSmemqOZvEXM3mMQgURytPzrY3v3R1NvDLX7SFFENbCMaGS/FVPYrT1W4Od2ncRLNhajKhMVpntmaf+3bn3A/UHUcrT7aa2cZtHaH3lvkK17SFIBUptIWMlyrdROgtc1hs3lVbWoEQKsK1R5uG49DDdbdPW0gRtIVgzKToJzRKm+88S7iO27wQvUu4RqAI1x6d36A/rN3KvC3nV5W+j0WuNWwLcRGnz+E6106DQbw/I4pJZXOMTcNx6PNRsNiscN1sGGubI1i8cz3apPJ8fjv8iRu+Ks7OSXnEwXP8uaHn6cMIwjWsXMcfsDcN15tWvlFvuzPeH/RbI2QcsTzaJFyH3hIiyWu1OeJsrXGkjr39BQUksImM5CNcU7mOWZbZiVVluFqBkBGuPWo3G2svO3Uugsq1z0A8iLQtZDBwlz+ExL4qCpZLIVhL0vkNiwcxXNnDYtP91UxmRMgI156tG5JjqFz7DMSxhuv+xCeQ2FdFAcbOtptqztkoZJl2KyNoJWCndfwcyL85Qka49mydRe+3W40oLnv6nKAXa1vI5KRPX5vuIGwJtFwv3Chkmat3tjyPBnU0HaZn9WEDoSBce3b17uonkHW+p45oC1muN7FcIeEaKbl6d72QHMvxEYu1p3bg9LWzJ1CF2r97zez7zcyZ2c9WPZYizm+3Vt6NLJaTh89A7CLtmJhcIYS2EMS+gcykR615nIvl+IjFtqbCNcvwIWS1fvea2ZdJ+lZJ76t6LEVlma08+Wbdik7d0HO93OQulr7WBUfA0snWaxUeGg3T2Xb481Gw3GSYzjLCNcJW23evmV0l6VclfYukhysezkpWqbQ0G6YzkUzc8JmHow3XE20hPU87WiJcpnSq12sVHnZaSawDjuNtIQRrhK7OJYE7JP0n59wfmNm/q3owq7hqZ0vSQaHHXr27Fc3JY1YgfuGb3nvsdqc/mHn/a571lGO381jD9US1mk1kICmp6vXVu1t65KC30uORhslAvUW4RuBqGa7N7FslPUnScwo89vmSni9J11133SmPrJhVKtfrrC5SR845r5VrxZmtj01i7PUJ10jLqv3TsRwfsVwjM5mZnHNqNQnXCFvtwrWZfa6kl0n6Sudcd9njnXN3aFjl1k033VSLSNZqZDrTbupSp7/0sbFM1pkXrKcr0q94x32SpBfdcsPi5/Myqvo53nMd608JzLbKcnxZJp0nXCclk5SLyjXCV8d38M2SHivpHjPrm1lf0ldLesHodrva4RVzfmf55xazOHZmlPyH4Vh7ridXCGG1EKSm1chO7MQ3z5mtphpZQj0zuNwiOb1yCBCa2lWuJf2mpLun7vslSX+tYUV7aTW7Ds5vt/SAjhY+Zjeik4fvMBxptj7WFpLnToOBUxbJewAo4vxOSwfdvNDjkJbx9CMq1whd7cK1c+4RSY9M3mdmlyQ95Jy7p5pRra7IrPgi1e1Q+A7DkWbrY20h0nBSYzuLY7UYoIjz2y197MLiwoNEuE7RuM5AzzVCxzv4lJzdbi7d1njVZanqzHfl2udW6nUy3QrSZVIjEnNuu1hRoejjEI9xW0iLq3kIXBBHL+fcU6sew6oamWl3a/GkRk4eaTnq5cqntjw/7ObR9N0DRRQ57mWZdHaL42NqxpG6SVsIAsc7+BQtO4nEtPOY97aQCAvXhzP6TC8V6D0FYtJsZNptL26FOttuMRchQZcr1w3+7RG2eNJdDS3qLdxtN6L6dO48d0nHuFrIpe7JqxgHM+5DvG69/a5jt+99YG/m/XfednNpY6rC+e2WDjrzP1hyVS9N41ZKdmhE6DiCnaJFExZj6reW/G/hnEWya+WkWSskFFk1AfG68drzVQ+hEssmNTKZMU2X20K4aoHAEa5P0ZkFbR+Lvhai7VYmM3/tHNtb8VUuZvXfF9loCPGIvSJd1LKVks5TuU5SZsMyTUxXdZEm3sGnqNXI5i6Gf2ZJz2FozEw7LX8/026Ek5lm9Vz3c8eKIUjOovkmZsMNZJAesyt910DICNenbF6IjvHksVNw57VCz+UxqNfBYOB02JvdAkLfNVLTbGRz1zLebjWYzJgo895gCFSDcH3KZlVgzeILj5K/anO7lUWzc+XYQS+f2zLDiiFI0bxj4HaEx0YUM6xcVz0KYHOE61M2q0K9sxVnZcbXB4ZdjxXwuljUW03fNVI073gRY+EBq4jv3Ij0EK5P2ay2kBhbQiR/bSE7rfhenwuHvbW+BsRqZ86kZZ/tZQgPlWvEgHB9ymatChLbSiFjvirOMVau9xYE6P2jXrTbvQPzzGv/oHKdNrI1YkC4PmXt5sn+4dhWChnbaTW8VB1iC9eDgdPe0fxwPRhI+7SGIDHze645LaWMyjViwFHslJnZiQpNrJWZLDv5s65jO7JwfbHb12DJanuLKttAjOYdK5jQmDbWC0EMCNclmK7ExHzy2HTb4kZmOhtZT/qFg+XBmb5rpGZWkSHLhlf7kDCyNSLAUawEk2HaLO6Tx6N2tzb6/vM7zehWUikSnKlcIzVZZmpPFx6aDTYRSRz/+ohBvCmvRibDdTvyk8fVu60Nv3+zcF5Hi/qtxw66uXo5OzUiLdNX8WJrCcPqYj4/Ih2E6xJMtoXEPlnnbLupRmP9g+PVO5uF87rp5QMddIptEkNrCFKz1cgW3kZ6iNaIAUeyEmw3r1RjYu63loZVh3UDspl0VWThev+o+CogqzwWiMGJtpDIiw8ogHSNCHAkK8FkoE7h5LFua8e57ZaakVWuLq4QmFd5LBCDk5XruIsPWI5sjRjElWRqanICY7sZ/8njUWv2XW/ar11H+53irR6rPBaIwdbU5O7p2wAQIo5kJcgyUzaapBHzSiFj57dbytb4MWMM16tUow+7uXJ2akRCCNeYRuUaMeBIVpLxAaMVWdvDLFlmOr+9elC+eieulUIGA6dL3eLh2jnpIjs1IiHTV/JSKD5gCVYLQQQ4kpVkvLxQc4OVNEKyat/1brsRXdXqoJcv3ZlxGuEaKZkO07EdA7C6NM6QiB1HspKMP4ynULmWVu+73nTzmTpaZ4LifoE1sYFYTE5ozLJ0jo8A4saRrCSpheurdlorXd2LMVyvE5RZMQQpOT4fJf7J3iiA0jUikEbSq4FMJpPUiGxr73majUznVui7jnEy4/4aLR7rfA8QstQKD1gsjTMkYsfRrCRm6W3rWrQ1ZGerEeXmOpfWCMp57nTUK7ajIxADG8WpViLzUQDEj3BdEjNLbhL0VQXDdYxV614+UKe34mzGEXZqREoyKtcAIsPRrCSmKxWaVBTto46x33qT3ul1Kt5AqMZX9FgpBEAsOJqVZNgWUvUoytVqZDrTbi59XIyV602W1GM5PqRkfFxsJjIfBUD8CNclSvHU8agzi4Nzu5Vpd2t5AA8N4RooJqUNtgCkgaNZScwsyXS9rOUjtl0ZxzZp7Tjo9jVgG3QkIqMtBEBkOJqVJMWea0k6t724Kn1+J76qtbRZ9XkwkA5ZMQSJoC0EQGwI1yVJtHCtnVZj4dreZwv0ZIfmqJern29WeaY1BKlgQiMmpXieRHziSzZ1luBRw8x0pt3U3uHs3QqLTHgMjY9gfLHT16d5GAtQd2wik65bb7/r2O17H9iT3Mn777zt5jKHBWwsvmRTU5ZkU8jQ2TnhutXMotw85rC7eUuHj+cAQjA+Lqayey3mu/Ha81UPAfCCcF2SFHdoHJvX+nG2HV+wlqQDD8GYta6RivFxsZHo8TFlVKQRK67D4dSdnTOp8Ww7vvWtpeFqH5tiQiNSYaM/GZVrAJEgXOPUza1cL1lJJFQ+Wjr6D1L/7wAAFIdJREFUuVO3v9726UBwqFoDiAjhGqduq5nNXAngbISbxwwGzlvVmb5rpIITEYCYcEwrUcq1mVlV6jMR9lwf9XM5T/u/HPTou0YaUp2PAiBOhOsyJXz+ODNVpd5uNdSMcOktH5MZT+O5gDojWwOISXzppsZSPn9Mt4XEumGEz1YO2kKQCsI1gJjE1/RaE7MWx3fOJbs4/nSYbjXiPJseeVzlw+dzAXWWJV16ABAbwnVJbrz2vAa+mnEDNB2mY92NbeDxn9jncwF1RuUaQEwI16cklYp0UVtTYbodaVuIzw9QKX8YQ1oI1wBiUruEY2YvNrM/N7M9M3vQzN5qZl9Q9biwmZNtIbV763nhMw+TrZEO0jWAeNQx4TxV0uskfbmkp0vqS3qnmT26ykFhM9NhuhVp5drJXyJ2pGskgmgNICa1awtxzt0yedvMniPpgqR/JOmtlQwKG2s1smOXfqfbRGLhtXLt76mAeiNdA4hI7cL1DOc0rLA/XPVAsJnJ6nVK4fqFb3rvsdud0bbm0/e/5llPOXabnmukgmwNICYhJJxXS/pLSXfN+qKZPd/M7jazux988MFyR4aVTPZdx7rOtd+2EG9PBQAASlLryrWZ/Yykr5D0Fc65mYv+OufukHSHJN10003EkRqbrFzHus71rOXzpivSr3jHfZKkF91yw8Ln4s2MVMR5NACQqtqGazN7paRvlPQ059zfVD0ebG4cqE2KcutzSWp4XFMsI3EgFazFByAitQzXZvZqDYP1U51z91U9HvgxrlxbxCfSdsvfh4btVsPbcwF1Fu8RAUCKaheuzey1kp4j6ZmSHjazx4++dNE5d7G6kWFTV8J1xQM5RdtNf4E41o12gFtvvzKF5t4H9iR3/D6JjbgAhKt24VrSC0b//f2p+39Y0kvLHQp8Gq8QYhHXqahcA6u58drzVQ8BALyqXbh2zsWbvBLXHPVcx9xL7LNy7fO5gDqhKg0gZlx3Rmnoua7uuQAAQDk4e6M0l1cLiTdbq93MvP18VK4BAAgP4RqluVy5rngcp8nMvG2QQ+UaAIDwcPZGaVJoC5H8TEQ0Y7UQAABCxNkbpWlk8beFSNKZrc3nCe9uNaP/EAIAQIwI1yjN5XBd8ThO21W7rc2fY2fz5wAAAOUjXKNUFvUq10NXewjGPgI6AAAoH+EapTJT9H0hu1uNy2t6r8tHQAcAAOUjXKN0cUfr4YTN8xuE42bDtLvFMnwAAISIcI1SmUVfuJa0WeX5/E6LyYwAAASKcI1Sxd9xPbTJhERaQgAACBfhGqUaVq7jD9ibtIWwUggAAOEiXKN08Ufr4YY5u+31+qY3CeYAAKBahGuUKoVgPXauvXpI3m41Lu9kCQAAwsNZHOVKKF2fWaNyvc73AACA+iBco1QJZWudba++DfqZNb4HAADUB+EaJUsnXu8SrgEASA7hGqVKYKGQy3ZbjZV/3jNsHgMAQNAI18ApyTLTzophmco1AABhI1yjVAkVriWt1nfdbmWsFAIAQOA4kwOnaHereLhe5bEAAKCeCNcoVQq7M05aZWk9luEDACB8hGvgFO20igfmVR4LAADqiXCNUqVVtx7uuHgajwUAAPVEuEa5EkvX7WZWeDm+7SbhGgCA0BGugVNkZmoXDM3tFr+OAACEjrM5SpVY4VqStF0gNJsNq9wAACBsnM2BU1akl7rdbCS3kgoAADEiXAOnrEjlushjAABA/XFGB05ZkZ5rVgoBACAOhGuUKsXWhyLBmXANAEAc2G8Zp+rW2+86dvuvPrYvs5P333nbzWUOq1RFdl5kd0YAAOJAuEapPv/Tz1c9hNLttBrKMmkwmP+YM21+FQEAiAFndJyqmCvSRZmZdreaunjUn/uYXdpCAACIAj3XQAnObM3/HLvdaqjZ4FcRAIAYcEYHSrC7oKd60dcAAEBYCNdACRZVrhd9DQAAhIVwDZRg0WogrBQCAEA8CNdACXapXAMAkATCNVCCRmba2ZpdoZ53PwAACA/hGijJrBDdaBi7MwIAEBHCNVCSWe0frG8NAEBcCNdASXZnVK7ZmREAgLgQroGSzArX9FsDABAXwjVQklkrhrBSCAAAcSFcAyXZbmXKpn7jqFwDABCX2oZrM3uBmX3IzI7M7D1m9pVVjwnYhNnJlUFmtYoAAIBw1TJcm9mtkl4t6WWSvljSuyW93cyuq3RgwIYm20BazUytRi1/BQEAwJrqemb/bklvcM693jn3QefcCyU9IOl/r3hcwEYmK9fbzbr++gEAgHXV7uxuZluS/qGk35360u9K+vLyRwT4szURqLcI1wAARKeOZ/fHSmpI+vjU/R+X9PjpB5vZ883sbjO7+8EHHyxjfMDaCNcAAMStzmd3N3XbZtwn59wdzrmbnHM3XXPNNeWMDFjT1kSPdbvJZEYAAGJTx3D9SUm5TlapH6eT1WwgKMcq10xmBAAgOrU7uzvnupLeI+kZU196hoarhgDBatMWAgBA1Oq6PdzPSPoVM/szSe+S9G2SPl3Sz1c6KmBDx9tCCNcAAMSmluHaOXenmT1G0g9IulbSPZK+xjn34WpHBmwmy0xmJucclWsAACJUy3AtSc6510l6XdXjAHzLNJxUwAYyAADEh7M7UDKz4X+bmVU7EAAA4B3hGiidyTRsEQEAAHEhXAMlM9OV8jUAAIgK4RoomY3+AACA+BCugbKRrAEAiBbhGigZXSEAAMSLcA2UziheAwAQKcI1ULJh1Zp4DQBAjAjXQMloCwEAIF6EawAAAMATwjVQMjN6rgEAiBXhGqgC6RoAgCgRroGSDTeRIV0DABAjwjVQNnI1AADRIlwDJWO1EAAA4kW4BgAAADwhXAMlM9EZAgBArAjXQNnoCQEAIFqEa6AC5GsAAOJEuAZKZhP/CwAA4kK4BgAAADwhXANlM+rWAADEinANlIxgDQBAvAjXQBVI2AAARIlwDVSAbA0AQJyaVQ8AiN2tt9917PZ9D+zLyZ24/87bbi5zWAAA4BQQroGS3fjp56seAgAAOCWEa+CUUZEGACAd9FwDAAAAnhCuAQAAAE8I1wAAAIAnhGsAAADAE8I1AAAA4AnhGgAAAPCEcA0AAAB4QrgGAAAAPCFcAwAAAJ4QrgEAAABPCNcAAACAJ4RrAAAAwBPCNQAAAOAJ4RoAAADwhHANAAAAeEK4BgAAADwhXAMAAACeEK4BAAAAT8w5V/UYvDGzByV9uOpxYKnHSvpk1YOoGK/BEK8Dr4HEazDG68BrMMbrEMZr8JnOuWum74wqXCMMZna3c+6mqsdRJV6DIV4HXgOJ12CM14HXYIzXIezXgLYQAAAAwBPCNQAAAOAJ4RpVuKPqAdQAr8EQrwOvgcRrMMbrwGswxusQ8GtAzzUAAADgCZVrAAAAwBPCNQAAAOAJ4RqlMLOvMrO3mNnfm5kzs+dVPaaymdmLzezPzWzPzB40s7ea2RdUPa4ymdm3m9n7Rq/BnpndZWZfW/W4qmRm3z/6nfjZqsdSJjN76ejnnvzzsarHVTYzu9bM3jg6JhyZ2b1m9tVVj6tMZva3M94Lzsx+p+qxlcXMGmb2o2b2odH74ENm9mNm1qx6bGUzs3Nm9ioz+7CZHZrZu83sS6oe1yqS+0dDZc5KukfSL4/+pOipkl4n6c8lmaQfkfROM7vROfdQlQMr0Uclfa+kv9bww/1zJf2mmf1D59z7Kh1ZBczsyyR9q6TkfvaRv9Lw92Isr2gclTCzqyW9S9IfS/paSQ9KeqKkT1Q5rgp8iaTGxO1rJb1H0v9dzXAq8b2Svl3DY+L7JX2RpDdK6kj60QrHVYVf0PDnf66G54x/pSvnyr+vdGQFMaERpTOzi5K+wzn3hqrHUiUzOyvpgqRnOufeWvV4qmJmD0l6sXPu9qrHUiYzu0rSezUM1/9O0j3Oue+odlTlMbOXSvpfnHNJXb2ZZGYvk/TVzrl/VPVY6sTMXiLp30r6dOfcQdXjKYOZ/bakTznnnjtx3xslPcY598+qG1m5zGxH0r6kr3fO/dbE/e+R9Hbn3A9UNrgV0BYCVOechr+DD1c9kCqMLoN+o4ZXNd5d9XgqcIek/+Sc+4OqB1KhJ45axT5kZm82sydWPaCSPVPSn5rZnWb2CTP7SzP7DjOzqgdWldHP/i2S/mMqwXrkjyU9zcxukCQzu1HS0yW9rdJRla+p4VWMo6n7DyV9RfnDWQ9tIUB1Xi3pLyXdVfVAymRmX6jhz7wt6aKkr3POvb/aUZXLzL5V0pMkPafqsVToTyU9T9J9kh4n6QckvdvMPt8596kqB1aiJ0p6gaRXSnq5pCdLes3oa0n14E94hqTP0rA1ICU/qWHB5V4zyzXMZz/unHtdtcMql3Nu38zukvQDZnaPpI9JepakmyX990oHtwLCNVABM/sZDT+Ff4VzLqk+Uw37bJ8s6WpJXy/pjWb2VOfcPdUOqxxm9rmSXibpK51z3arHUxXn3Nsnb5vZn0j6Gw37LH+mkkGVL5N0t3PuxaPbf2Fmn61h722q4fpbJf25c+4vqx5IyW6V9E2Sni3pAxoeI19tZh9yzv2HSkdWvudI+kUN+61zDdvn3iTpKVUOahW0hQAlM7NXavhJ/OnOub+pejxlc851nXP/3Tk3DhV/Ken/qHpcJbpZ0mMl3WNmfTPrS/pqSS8Y3W5XO7xqOOcuahgqPrvqsZToAUn3Tt33QUnXVTCWypnZ4yT9C0mvr3osFfgpST/tnHuzc+79zrlf0fBD5ouXfF90nHP/wzn31Rq2DD7BOfc/S2pJ+lC1IyuOyjVQIjN7taRvlPRU59x9VY+nJjJJKQXK35R099R9v6ThCiovk5RkNdvMtiXdIOkPqx5Lid4l6XOn7vscSR+uYCx18M0aro7x5qoHUoFdnVwtJ1fCRVDn3CVJl8zsUZJukfSiiodUGOEapRitjPGk0c1M0nVm9mRJDznn/q66kZXHzF6r4eWuZ0p62MweP/rSxVHVLnpm9nJJvyPpIxr2Fz5bw6XYklnr2jn3iKRHJu8zs0sa/i4k0RojSWb205LeKunvNOy5/kFJZzRcfiwVr9Swz/wlku6U9MWS/o2k7690VBUYTWT815Le7Jzbr3o8FXirpO8zsw9peAXniyV9txJcutbMbtEwJ9ynYW74KQ3bCX+pynGtgqX4UAoze6pmV6Te6Jx7XrmjqYaZzftl+2Hn3EvLHEtVzOwNkp4m6fEaLkP4Pkk/5Zx7R5XjqpqZ/ZHSW4rvzZK+SsMWmQcl/YmkH3TOTbdJRG20idLLNKxg/52GvdavcYmdnM3saZL+QNKXOuf+rOrxlM3Mzmm4nvXXafhh8wENK/g/4pybXjkjamb2DZJ+QtJnSHpI0m9Ieolz7kKlA1sB4RoAAADwJNleHgAAAMA3wjUAAADgCeEaAAAA8IRwDQAAAHhCuAYAAAA8IVwDAAAAnhCuAeAUmNlLzcyZWS026zKz543Gc/3EfX87Wnt8fPupo3FzbgCANXEABYB0fZ2GG1eMPVXSD4lzAwCsrRYVFQBA+Zxzf1HF/6+ZtST1U9uFEEAaqE4AwOn6PDP7QzM7MLMHzOxHJtsuzGzbzF5pZveY2UUz+5iZvdXMbph8kom2ji8zs181sz0zu9/M/i8z25567BPN7HdG/58PmtmrJbWnBzbZFmJmL9Wwai1JvdH/18Lwa2bfYWZ3mdlDZvaImf3JaDvvycdcP3quF5jZK8zsfkkdSVeb2RvM7KNmdpOZvdvMDs3sr8bPYWbfPRrjnpn9lpldU/A1B4DKULkGgNP1m5J+UdJPSLpF0g9KGkh66ejrbUnnJP2YpAckPVrSCyT9iZnd4Jz72NTz/YqkN0n6l5JuHj3PwxoFYzPbkvR7knYkfbukT0i6bfT4RX5B0mdI+hZJXyEpL/CzXT/6vr/V8HzyzyX9tpl9jXPu7VOPfYmkP5f0fEkNSUej+89L+mVJPy3p/tHjfsPMXivpc0Y/w6dJepWk10r6hgLjAoDKEK4B4HS93jn38tHff9fMzkv6HjN7lXPuEefcBUn/evxgM2tIeoekj0t6lqRXTj3frznnxhXmd5rZl44eN77vuZKeKOlm59yfjJ7z7ZLev2iQzrmPmtlHRzf/1DnXX/aDOef+z4lxZ5J+X8NA/G2SpsP1x/X/t3fvoFEFUQCG/4ONBkGwkSDRTkHtgviqA4KK2kTxARYKQdBGELHSwlLsbKy0UgsRjWBhlUZEC8VXClFQNATBB5gixjgWMxfWddfE5C4E83/N3Rlm75xtlnOHM3Nhd2MpSERAfrAYSCkNlb4PwBNgO7AmpTRZ+tcBxyJiQdUnSXORZSGS1FnXm9pXgcXAuqojIvoj4kFEfAF+AGNlzOoW97vT1H4KrGhobwLeVYk1QErpZ4s4Zi0ieiNiMCJGyXFPAH20jvtmmxrrsSqxLobL9V5TEj1MXhDqriF0SeoYk2tJ6qzRNu3lABGxA7gGvAT2ARuA9cBHYCF/+tTUHuf3euruFnO2imNWIqKHvFK9FDgGbCbHfZfWcY+0udWXxkZK6Xv5+LlpXNXf6t6SNGdYFiJJnbUMeN3UBnhfrnuBVymlQ9WAcprG0hnONwKsbRNHnbYCS4D+lFJVTkJEdLUZ78kgkuYFV64lqbOaN+DtBb4Bz0q7i1xS0eggedPfTNwHeiJiY9VR6qGnsxFwvFwXTWNslURPNMyzCtgyzTgl6b/kyrUkddaRktw+JJ8Wchg4k1KqyiHuArsi4gIwCPQCx2kql/gHl4FTwI2IOE0+LWSAfCrHVF6U64myCXIypfSozdh75IeCKxFxnlyOchZ4iws3kuYx/wAlqbN2kjf53QIOkI/ca3wr4iXgHLAHuA1sIx9p93Umk5Wa5T7gMXCRnGy/KfNOZbB85yh5BfzhX+Z5DuwHVpJ/20lyUj/U7juSNB+EL8iSJEmS6uHKtSRJklQTk2tJkiSpJibXkiRJUk1MriVJkqSamFxLkiRJNTG5liRJkmpici1JkiTVxORakiRJqonJtSRJklSTX1cOgGOFMCmHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#alter plot size so it looks decent\n",
    "#makes viz bigger\n",
    "import matplotlib.pyplot as plt\n",
    "BIG = 16\n",
    "MED = 14\n",
    "SMALL = 10\n",
    "plt.rcParams.update({'font.size': BIG})\n",
    "plt.rcParams.update({'axes.labelsize': BIG})\n",
    "plt.rcParams.update({'xtick.labelsize': MED})\n",
    "plt.rcParams.update({'ytick.labelsize': MED})\n",
    "plt.rcParams.update({'figure.figsize':[12, 8]}) #this is important as it makes the visualizations much easier to read and clip/export!(w,h)\n",
    "\n",
    "#plot reward stack and arms\n",
    "plt.xticks(ticks=list(range(1,k+1)), labels=list(range(1,k+1)))\n",
    "\n",
    "plt.xlabel(\"bandit arm\")\n",
    "\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.violinplot(reward_stack, list(range(0,k)), points=20, widths=0.3,\n",
    "                     showmeans=True, showextrema=True, showmedians=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward from random selection: 6670.930758002051\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "0    0.110\n",
      "1    0.104\n",
      "2    0.087\n",
      "3    0.109\n",
      "4    0.101\n",
      "5    0.074\n",
      "6    0.104\n",
      "7    0.108\n",
      "8    0.109\n",
      "9    0.094\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#random selection without any value assesments\n",
    "\n",
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set objects needed\n",
    "arms_selected = []\n",
    "total_reward = 0\n",
    "\n",
    "for i in range(0,n):\n",
    "    \n",
    "    #randomly pick an arm\n",
    "    current_arm = np.random.choice(range(0,k))\n",
    "    \n",
    "    #append choice to list tracking what was done\n",
    "    arms_selected.append(current_arm)\n",
    "    \n",
    "    #randomly pick a reward from the distrib\n",
    "    current_reward = np.random.choice(reward_stack[current_arm])\n",
    "    \n",
    "    #add current reward to total rewards\n",
    "    total_reward = total_reward + current_reward\n",
    "    \n",
    "\n",
    "print(\"total reward from random selection:\",total_reward)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(pd.Series(arms_selected).value_counts(normalize = True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epsilon greedy solution\n",
    "\n",
    "#example for setting base vars\n",
    "n = 1000\n",
    "reward_step = .9 #used with nonstationary tracking, set to one for stationary problems\n",
    "epsilon = 0.1\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "##############################################################################################\n",
    "#some basic helper functions\n",
    "##############################################################################################\n",
    "\n",
    "#use epsilon to make explouit or explore decision:\n",
    "def exploit_or_explore(epsilon):\n",
    "    \n",
    "    exp = np.random.binomial(1, epsilon, 1)\n",
    "    \n",
    "    return exp\n",
    "\n",
    "#value assesment\n",
    "def arm_max(expected_rewards):\n",
    "    \n",
    "    maxx = np.argsort(expected_rewards)[-1]\n",
    "    \n",
    "    #debug\n",
    "    #print(expected_rewards)\n",
    "    #print(maxx)\n",
    "    \n",
    "    return maxx\n",
    "    \n",
    "#pull the arm selected\n",
    "def pull_arm(current_arm):\n",
    "    \n",
    "    current_reward = np.random.choice(reward_stack[current_arm])\n",
    "    \n",
    "    return current_reward   \n",
    "\n",
    "##############################################################################################\n",
    "#some not so basic helper functions\n",
    "##############################################################################################\n",
    "\n",
    "#update reward expectations\n",
    "def update_reward_expectation(expected_rewards, last_reward_list, reward_step, current_arm):\n",
    "    \n",
    "    prior_tweaked = (reward_step * (last_reward_list[current_arm] - expected_rewards[current_arm]))\n",
    "    \n",
    "    #debug\n",
    "    #print(prior_tweaked)\n",
    "    \n",
    "    expected_rewards[current_arm] = expected_rewards[current_arm] + prior_tweaked\n",
    "    \n",
    "    #print(expected_rewards)\n",
    "    \n",
    "    return expected_rewards\n",
    "\n",
    "#when epsilon is used for exploration\n",
    "#select arm that has been selected the least number of times or random arm (not selecting the max arm)\n",
    "def arm_explore(expected_rewards, count_arms_selected):\n",
    "         \n",
    "    #get the number of times each arm has been selected\n",
    "    arm_breakdown = np.array(count_arms_selected)\n",
    "    \n",
    "    #check if first two are equal\n",
    "    sorted_arm_indices = arm_breakdown.argsort()\n",
    "    \n",
    "    #debug\n",
    "    #print(arm_breakdown)\n",
    "    #print(sorted_arm_indices)\n",
    "    #print(\"0:\",arm_breakdown[sorted_arm_indices[0]])\n",
    "    #print(\"1:\",arm_breakdown[sorted_arm_indices[1]])\n",
    "    \n",
    "    #if first do not have equal counts then return lowest count\n",
    "    if arm_breakdown[sorted_arm_indices[0]] != arm_breakdown[sorted_arm_indices[1]]:\n",
    "        return sorted_arm_indices[0]\n",
    "            \n",
    "    #take random sample\n",
    "    max_arm = arm_max(expected_rewards)\n",
    "    \n",
    "    rando_list = [i for i in range(0,k)]\n",
    "    \n",
    "    rando_list.remove(max_arm)\n",
    "    \n",
    "    selected_element = np.random.choice(rando_list)\n",
    "    \n",
    "    return selected_element\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "#main calls\n",
    "##############################################################################################\n",
    "#play one turn\n",
    "def play_one(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step):\n",
    "    \n",
    "    if epsilon > 0:\n",
    "    \n",
    "        #get explore/exploit signal\n",
    "        exp = exploit_or_explore(epsilon)\n",
    "        \n",
    "    else:\n",
    "        exp = 0\n",
    "    \n",
    "    #explore\n",
    "    if exp:\n",
    "        current_arm = arm_explore(expected_rewards, count_arms_selected)\n",
    "    \n",
    "    #exploit\n",
    "    else:\n",
    "        current_arm = arm_max(expected_rewards)\n",
    "        \n",
    "        #debug\n",
    "        #print(current_arm)\n",
    "        \n",
    "    #pull the arm\n",
    "    current_reward = pull_arm(current_arm)\n",
    "    \n",
    "    #append reward to reward_list\n",
    "    last_reward_list[current_arm] = current_reward\n",
    "    \n",
    "    #append arms selected to tracking\n",
    "    count_arms_selected[current_arm] += 1  \n",
    "    \n",
    "    #print(current_arm)\n",
    "    \n",
    "    #update reward expectation\n",
    "    expected_rewards = update_reward_expectation(expected_rewards, last_reward_list, reward_step, current_arm)\n",
    "    \n",
    "    #update total reward\n",
    "    total_reward = total_reward + current_reward\n",
    "    \n",
    "    return expected_rewards, last_reward_list, count_arms_selected, total_reward\n",
    "\n",
    "##############################################################################################\n",
    "#play thru\n",
    "##############################################################################################\n",
    "def play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first):\n",
    "\n",
    "    start = 0\n",
    "    \n",
    "    if explore_first:\n",
    "        \n",
    "        start = k\n",
    "    \n",
    "        #for first k rounds pull each arm available once to get started    \n",
    "        for current_arm in range(0,k):\n",
    "            #debug\n",
    "            #print(i)\n",
    "            current_reward = pull_arm(current_arm)\n",
    "\n",
    "            #append arms selected to tracking\n",
    "            count_arms_selected[current_arm] += 1  \n",
    "\n",
    "            expected_rewards[current_arm] = current_reward\n",
    "\n",
    "            #update total reward\n",
    "            total_reward = total_reward + current_reward\n",
    "\n",
    "            #debug\n",
    "            #print(total_reward)\n",
    "     \n",
    "    #play thru remaining rounds\n",
    "    for i in range(start,n):\n",
    "        #debug\n",
    "        #print(i)\n",
    "    \n",
    "        #start the process using epsilon greedy\n",
    "        expected_rewards, last_reward_list, count_arms_selected, total_reward = play_one(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step)  \n",
    "        \n",
    "    return expected_rewards, last_reward_list, count_arms_selected, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create run tracking\n",
    "dummy_list = []\n",
    "columns = [\"explore first\", \"epsilon\", \"reward step\", \"total rewards\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward =  8919.26068606617 \n",
      "epsilon =  0 \n",
      "reward step =  1\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "total times each arm selected: [   0    0    0    0    0    0    0    0    0 1000]\n",
      "final expected rewards: [0 0 0 0 0 0 0 0 0 9]\n",
      "final last rewards: [0 0 0 0 0 0 0 0 0 9]\n"
     ]
    }
   ],
   "source": [
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set to one as this is stationary\n",
    "reward_step = 1 #used with nonstationary tracking, set to one for stationary problems\n",
    "\n",
    "#set to 0 so its totally greedy with no exploration\n",
    "epsilon = 0\n",
    "\n",
    "#set explore first to 1 to have algo pull each arm once\n",
    "explore_first = 0\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "expected_rewards, last_reward_list, count_arms_selected, total_reward = play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first)\n",
    "\n",
    "print(\"total reward = \" ,total_reward, \"\\nepsilon = \", epsilon,\"\\nreward step = \", reward_step)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(\"total times each arm selected:\", count_arms_selected)\n",
    "print(\"final expected rewards:\", expected_rewards)\n",
    "print(\"final last rewards:\", last_reward_list)\n",
    "\n",
    "dummy_list.append([explore_first, epsilon, reward_step, total_reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward =  9323.807450218368 \n",
      "epsilon =  0.1 \n",
      "reward step =  1\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "total times each arm selected: [ 11  11  12  42  15  14 556  11 150 178]\n",
      "final expected rewards: [ 5  4  2  8  6  4 11  5  7  7]\n",
      "final last rewards: [ 5  4  2  8  6  4 11  5  7  7]\n"
     ]
    }
   ],
   "source": [
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set to one as this is stationary\n",
    "reward_step = 1 #used with nonstationary tracking, set to one for stationary problems\n",
    "\n",
    "#set to 0.1 so we eplore 10% of the time\n",
    "epsilon = 0.1\n",
    "\n",
    "#set explore first to 1 to have algo pull each arm once\n",
    "explore_first = 0\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "expected_rewards, last_reward_list, count_arms_selected, total_reward = play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first)\n",
    "\n",
    "print(\"total reward = \" ,total_reward, \"\\nepsilon = \", epsilon,\"\\nreward step = \", reward_step)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(\"total times each arm selected:\", count_arms_selected)\n",
    "print(\"final expected rewards:\", expected_rewards)\n",
    "print(\"final last rewards:\", last_reward_list)\n",
    "\n",
    "dummy_list.append([explore_first, epsilon, reward_step, total_reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward =  9679.962088834905 \n",
      "epsilon =  0.01 \n",
      "reward step =  1\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "total times each arm selected: [  1   3   1  35   0   2 692   0  34 232]\n",
      "final expected rewards: [ 3  3  2  7  0  6 10  0  6  6]\n",
      "final last rewards: [ 3  3  2  7  0  6 10  0  6  6]\n"
     ]
    }
   ],
   "source": [
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set to one as this is stationary\n",
    "reward_step = 1 #used with nonstationary tracking, set to one for stationary problems\n",
    "\n",
    "#set to 0.01 so we eplore 1% of the time\n",
    "epsilon = 0.01\n",
    "\n",
    "#set explore first to 1 to have algo pull each arm once\n",
    "explore_first = 0\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "expected_rewards, last_reward_list, count_arms_selected, total_reward = play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first)\n",
    "\n",
    "print(\"total reward = \" ,total_reward, \"\\nepsilon = \", epsilon,\"\\nreward step = \", reward_step)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(\"total times each arm selected:\", count_arms_selected)\n",
    "print(\"final expected rewards:\", expected_rewards)\n",
    "print(\"final last rewards:\", last_reward_list)\n",
    "\n",
    "dummy_list.append([explore_first, epsilon, reward_step, total_reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward =  9705.40214552488 \n",
      "epsilon =  0.01 \n",
      "reward step =  0.9\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "total times each arm selected: [  1   0   3   0   1   1 713   0 152 129]\n",
      "final expected rewards: [4 0 1 0 5 2 6 0 6 9]\n",
      "final last rewards: [ 5  0  2  0  6  3  6  0  6 10]\n"
     ]
    }
   ],
   "source": [
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set to one as this is stationary\n",
    "reward_step = .9 #used with nonstationary tracking, set to one for stationary problems\n",
    "\n",
    "#set to 0.01 so we eplore 1% of the time\n",
    "epsilon = 0.01\n",
    "\n",
    "#set explore first to 1 to have algo pull each arm once\n",
    "explore_first = 0\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "expected_rewards, last_reward_list, count_arms_selected, total_reward = play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first)\n",
    "\n",
    "print(\"total reward = \" ,total_reward, \"\\nepsilon = \", epsilon,\"\\nreward step = \", reward_step)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(\"total times each arm selected:\", count_arms_selected)\n",
    "print(\"final expected rewards:\", expected_rewards)\n",
    "print(\"final last rewards:\", last_reward_list)\n",
    "\n",
    "dummy_list.append([explore_first, epsilon, reward_step, total_reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward =  9933.09138295076 \n",
      "epsilon =  0 \n",
      "reward step =  1\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "total times each arm selected: [  1   1   1   3   1   1 933   1  48  10]\n",
      "final expected rewards: [5 5 1 7 6 5 9 5 4 6]\n",
      "final last rewards: [0 0 0 7 0 0 9 0 4 6]\n"
     ]
    }
   ],
   "source": [
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set to one as this is stationary\n",
    "reward_step = 1 #used with nonstationary tracking, set to one for stationary problems\n",
    "\n",
    "#set to 0 so its totally greedy with no exploration\n",
    "epsilon = 0\n",
    "\n",
    "#set explore first to 1 to have algo pull each arm once\n",
    "explore_first = 1\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "expected_rewards, last_reward_list, count_arms_selected, total_reward = play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first)\n",
    "\n",
    "print(\"total reward = \" ,total_reward, \"\\nepsilon = \", epsilon,\"\\nreward step = \", reward_step)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(\"total times each arm selected:\", count_arms_selected)\n",
    "print(\"final expected rewards:\", expected_rewards)\n",
    "print(\"final last rewards:\", last_reward_list)\n",
    "\n",
    "dummy_list.append([explore_first, epsilon, reward_step, total_reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward =  9056.193912143735 \n",
      "epsilon =  0.1 \n",
      "reward step =  1\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "total times each arm selected: [ 11  11  13  59  13  11 412  16 141 313]\n",
      "final expected rewards: [5 3 0 6 7 4 8 6 8 6]\n",
      "final last rewards: [5 3 0 6 7 4 8 6 8 6]\n"
     ]
    }
   ],
   "source": [
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set to one as this is stationary\n",
    "reward_step = 1 #used with nonstationary tracking, set to one for stationary problems\n",
    "\n",
    "#set to 0.1 so we eplore 10% of the time\n",
    "epsilon = 0.1\n",
    "\n",
    "#set explore first to 1 to have algo pull each arm once\n",
    "explore_first = 1\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "expected_rewards, last_reward_list, count_arms_selected, total_reward = play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first)\n",
    "\n",
    "print(\"total reward = \" ,total_reward, \"\\nepsilon = \", epsilon,\"\\nreward step = \", reward_step)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(\"total times each arm selected:\", count_arms_selected)\n",
    "print(\"final expected rewards:\", expected_rewards)\n",
    "print(\"final last rewards:\", last_reward_list)\n",
    "\n",
    "dummy_list.append([explore_first, epsilon, reward_step, total_reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward =  8956.157074884322 \n",
      "epsilon =  0.01 \n",
      "reward step =  1\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "total times each arm selected: [  2   2   2  69   2   2  38   3 329 551]\n",
      "final expected rewards: [5 5 3 6 6 4 6 2 6 7]\n",
      "final last rewards: [5 5 3 6 6 4 6 2 6 7]\n"
     ]
    }
   ],
   "source": [
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set to one as this is stationary\n",
    "reward_step = 1 #used with nonstationary tracking, set to one for stationary problems\n",
    "\n",
    "#set to 0.01 so we eplore 1% of the time\n",
    "epsilon = 0.01\n",
    "\n",
    "#set explore first to 1 to have algo pull each arm once\n",
    "explore_first = 1\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "expected_rewards, last_reward_list, count_arms_selected, total_reward = play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first)\n",
    "\n",
    "print(\"total reward = \" ,total_reward, \"\\nepsilon = \", epsilon,\"\\nreward step = \", reward_step)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(\"total times each arm selected:\", count_arms_selected)\n",
    "print(\"final expected rewards:\", expected_rewards)\n",
    "print(\"final last rewards:\", last_reward_list)\n",
    "\n",
    "dummy_list.append([explore_first, epsilon, reward_step, total_reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward =  9667.99378251641 \n",
      "epsilon =  0.01 \n",
      "reward step =  0.9\n",
      "the maximum mean is : [10]\n",
      "the best arm is : 6\n",
      "total times each arm selected: [  2   2   2   4   2   1 657   4  88 238]\n",
      "final expected rewards: [ 3  3  1  6  6  5 10  3  6  6]\n",
      "final last rewards: [ 3  4  1  7  7  0 11  3  6  6]\n"
     ]
    }
   ],
   "source": [
    "#set base vars\n",
    "n = 1000\n",
    "\n",
    "#set to one as this is stationary\n",
    "reward_step = .9 #used with nonstationary tracking, set to one for stationary problems\n",
    "\n",
    "#set to 0.01 so we eplore 1% of the time\n",
    "epsilon = 0.01\n",
    "\n",
    "#set explore first to 1 to have algo pull each arm once\n",
    "explore_first = 1\n",
    "\n",
    "#set objects needed\n",
    "count_arms_selected = np.array([0 for i in list(range(0,k))])\n",
    "last_reward_list = np.array([0 for i in list(range(0,k))])\n",
    "expected_rewards = np.array([0 for i in list(range(0,k))])\n",
    "total_reward = 0\n",
    "\n",
    "expected_rewards, last_reward_list, count_arms_selected, total_reward = play_the_bandit(expected_rewards, last_reward_list, count_arms_selected, total_reward, epsilon, reward_step, n, explore_first)\n",
    "\n",
    "print(\"total reward = \" ,total_reward, \"\\nepsilon = \", epsilon,\"\\nreward step = \", reward_step)\n",
    "print(\"the maximum mean is :\", max_mean)\n",
    "print(\"the best arm is :\", best_arm)  \n",
    "print(\"total times each arm selected:\", count_arms_selected)\n",
    "print(\"final expected rewards:\", expected_rewards)\n",
    "print(\"final last rewards:\", last_reward_list)\n",
    "\n",
    "dummy_list.append([explore_first, epsilon, reward_step, total_reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explore first</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>reward step</th>\n",
       "      <th>total rewards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8919.260686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9323.807450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9679.962089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9705.402146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9933.091383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9056.193912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8956.157075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9667.993783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   explore first  epsilon  reward step  total rewards\n",
       "0              0     0.00          1.0    8919.260686\n",
       "1              0     0.10          1.0    9323.807450\n",
       "2              0     0.01          1.0    9679.962089\n",
       "3              0     0.01          0.9    9705.402146\n",
       "4              1     0.00          1.0    9933.091383\n",
       "5              1     0.10          1.0    9056.193912\n",
       "6              1     0.01          1.0    8956.157075\n",
       "7              1     0.01          0.9    9667.993783"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data = dummy_list, columns = columns)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
